{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122dbb57",
   "metadata": {},
   "source": [
    "# **Check GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    print(\"âœ… You are running in Google Colab\")\n",
    "    print(f\"ðŸ“ Python version: {sys.version}\")\n",
    "else:\n",
    "    print(\"âš ï¸ You are not running in Google Colab\")\n",
    "    print(\"This notebook is designed to run in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bf0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about RAM\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"ðŸ’¾ Total RAM: {ram_gb:.2f} GB\")\n",
    "\n",
    "# Information about CPU\n",
    "cpu_count = psutil.cpu_count()\n",
    "print(f\"âš™ï¸ CPUs available: {cpu_count}\")\n",
    "\n",
    "# Check GPU\n",
    "gpu_info = !nvidia-smi --query-gpu=name,memory.total --format=csv,noheader 2>/dev/null\n",
    "if gpu_info:\n",
    "    print(f\"ðŸŽ® GPU: {gpu_info[0]}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Not GPU available (using CPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f87264",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e43070",
   "metadata": {},
   "source": [
    "# **Preliminares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo optuna botorch gpytorch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8db664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ealeongomez/MSRRFF-Wind-Forecast.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62586a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math, pickle\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import griddata\n",
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import optuna.importance\n",
    "#from optuna_integration.botorch import BoTorchSampler\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.samplers import GPSampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_parallel_coordinate\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68173464",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_trials_per_type = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2d3d6",
   "metadata": {},
   "source": [
    "# **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16510715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_environment():\n",
    "    # Kaggle\n",
    "    if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
    "        return \"Kaggle\"\n",
    "\n",
    "    # Google Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        pkl_filename = \"/content/MSRRFF-Wind-Forecast/data/processed/data_dict.pkl\"\n",
    "        return \"Google Colab\", pkl_filename\n",
    "    except ImportError:\n",
    "        pass\n",
    "    # Local u otro entorno\n",
    "    return \"Local/Other\"\n",
    "\n",
    "value_, pkl_filename = detect_environment()\n",
    "\n",
    "print(\"Entorno detectado:\", value_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430cd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_filename, \"rb\") as f:\n",
    "    data_dict_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(X_arr, y_arr, batch_size, shuffle=False):\n",
    "    ds = TensorDataset(torch.tensor(X_arr, dtype=torch.float32), torch.tensor(y_arr, dtype=torch.float32))\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb33838",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_TSF = ['Synthetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_loaded[names_TSF[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_loaded[names_TSF[0]]['Max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(data_dict_loaded[names_TSF[0]]['time_series'])\n",
    "plt.title(names_TSF[0])\n",
    "plt.xlim(0, len(data_dict_loaded[names_TSF[0]]['time_series']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for folder_name in names_TSF:\n",
    "    print(f\"\\nFolder: {folder_name}\")\n",
    "\n",
    "    # Inicializar secciÃ³n\n",
    "    data[folder_name] = {}\n",
    "\n",
    "    X = data_dict_loaded[f\"{folder_name}\"]['X']\n",
    "    Y = data_dict_loaded[f\"{folder_name}\"]['Y']\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    X = X[..., np.newaxis]  # Expand dims for CNN\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    # Train/Validation/Test splits\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "    if folder_name == \"Etiopia-April\" or folder_name == \"Etiopia-May\":\n",
    "        batch_size = 64\n",
    "    else:\n",
    "        batch_size = 256\n",
    "\n",
    "    train_loader = make_loader(X_train, y_train, batch_size)\n",
    "    valid_loader = make_loader(X_valid, y_valid, batch_size)\n",
    "    test_loader  = make_loader(X_test,  y_test, batch_size)\n",
    "\n",
    "    data[folder_name] = {\"loaders\": {\"train\": train_loader, \"valid\": valid_loader, \"test\":  test_loader}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data[folder_name][\"loaders\"][\"train\"]))\n",
    "if isinstance(batch, (list, tuple)):\n",
    "    _, y_sample = batch\n",
    "else:\n",
    "    y_sample = batch[\"y\"]\n",
    "H = y_sample.shape[1]\n",
    "print(f\"Usando dataset: {folder_name} | Horizonte H={H}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4abba",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26f65c",
   "metadata": {},
   "source": [
    "## Tradictional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainRNN_Forecaster(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo recurrente tradicional para predicciÃ³n multihorizonte.\n",
    "    Compatible con RNN, GRU y LSTM.\n",
    "\n",
    "    EcuaciÃ³n general:\n",
    "        h_t = f(W_xh * x_t + W_hh * h_{t-1} + b)\n",
    "        yÌ‚ = W_hy * h_T + b_y\n",
    "\n",
    "    ParÃ¡metros:\n",
    "        horizon: nÃºmero de pasos de predicciÃ³n\n",
    "        rnn_type: \"RNN\", \"GRU\" o \"LSTM\"\n",
    "        hidden: tamaÃ±o del estado oculto\n",
    "        num_layers: nÃºmero de capas recurrentes\n",
    "        bidirectional: True/False\n",
    "        pool: \"last\" o \"mean\"\n",
    "    \"\"\"\n",
    "    def __init__(self, horizon=24, rnn_type=\"RNN\", hidden=64,\n",
    "                 num_layers=1, bidirectional=False, pool=\"last\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.horizon = horizon\n",
    "        self.rnn_type = rnn_type\n",
    "        self.hidden = hidden\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.pool = pool\n",
    "\n",
    "        # Capa recurrente pura\n",
    "        self.rnn = getattr(nn, rnn_type)(\n",
    "            input_size=1,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        # Capa lineal final\n",
    "        out_dim = hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, T, 1]\n",
    "        Salida: [B, horizon]\n",
    "        \"\"\"\n",
    "        H, _ = self.rnn(x)  # [B, T, hidden]\n",
    "        if self.pool == \"mean\":\n",
    "            v = H.mean(dim=1)        # promedio temporal\n",
    "        else:\n",
    "            v = H[:, -1, :]          # Ãºltimo estado\n",
    "        y_hat = self.fc(v)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f872f",
   "metadata": {},
   "source": [
    "## Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9918f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRFF_PT(nn.Module):\n",
    "    \"\"\"\n",
    "    ImplementaciÃ³n de Random Fourier Features (RFF)\n",
    "    - Compatible con kernel gaussiano o laplaciano.\n",
    "    - ProyecciÃ³n: Î¦(x) = sqrt(2/Nf) * cos(Wx + b)\n",
    "    - Soporta parÃ¡metros entrenables para escala espectral.\n",
    "    \"\"\"\n",
    "    def __init__(self, Nf, scale=None, gamma=None, normalization=True,\n",
    "                 function=\"cos\", trainable_scale=True, trainable_W=True,\n",
    "                 seed=None, kernel='gaussian'):\n",
    "        super().__init__()\n",
    "        self.Nf = Nf\n",
    "        self.gamma = gamma\n",
    "        self.scale = scale\n",
    "        self.normalization = normalization\n",
    "        self.function = function\n",
    "        self.trainable_scale = trainable_scale\n",
    "        self.trainable_W = trainable_W\n",
    "        self.seed = seed\n",
    "        self.kernel_type = kernel\n",
    "\n",
    "        # InicializaciÃ³n diferida\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.rho_scale = None\n",
    "        self._eps = 1e-8\n",
    "        self.bandwidth_history = []\n",
    "\n",
    "    def _get_random_features_initializer(self, shape, sigma=1.0, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        if self.kernel_type == 'gaussian':\n",
    "            return np.random.randn(*shape) / sigma\n",
    "        elif self.kernel_type == 'laplacian':\n",
    "            return np.random.laplace(loc=0.0, scale=1.0, size=shape) / sigma\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported initializer {self.kernel_type}')\n",
    "\n",
    "    def _ensure_params_initialized(self, device, D):\n",
    "        if self.W is None:\n",
    "            if self.gamma is not None:\n",
    "                sigma = np.sqrt(1.0 / (2 * self.gamma))\n",
    "            else:\n",
    "                sigma = 1.0\n",
    "            if self.scale is None:\n",
    "                self.scale = sigma\n",
    "\n",
    "            W_init = self._get_random_features_initializer((D, self.Nf),\n",
    "                                                           sigma=self.scale,\n",
    "                                                           seed=self.seed)\n",
    "            self.W = nn.Parameter(torch.tensor(W_init, dtype=torch.float32, device=device),\n",
    "                                  requires_grad=self.trainable_W)\n",
    "\n",
    "            b_init = np.random.uniform(0.0, 2 * np.pi, size=(self.Nf,))\n",
    "            self.b = nn.Parameter(torch.tensor(b_init, dtype=torch.float32, device=device),\n",
    "                                  requires_grad=self.trainable_W)\n",
    "\n",
    "            init_kernel_scale = 1.0\n",
    "            rho0 = np.log(np.exp(init_kernel_scale) - 1.0)\n",
    "            self.rho_scale = nn.Parameter(\n",
    "                torch.tensor([rho0], dtype=torch.float32, device=device),\n",
    "                requires_grad=self.trainable_scale\n",
    "            )\n",
    "\n",
    "    def _kernel_scale(self):\n",
    "        return F.softplus(self.rho_scale) + self._eps\n",
    "\n",
    "    def bandwidth_lengthscale(self):\n",
    "        if self.rho_scale is None or self.scale is None:\n",
    "            return None\n",
    "        ks = float(self._kernel_scale().detach().cpu().item())\n",
    "        return float(self.scale) / ks\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def log_bandwidth(self, step):\n",
    "        ell = self.bandwidth_lengthscale()\n",
    "        if ell is not None:\n",
    "            self.bandwidth_history.append((step, float(ell)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = inputs.device\n",
    "        if inputs.dim() == 2:\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "        elif inputs.dim() != 3:\n",
    "            raise ValueError(f\"Expected [B,T,D], got {inputs.shape}\")\n",
    "\n",
    "        B, T, D = inputs.shape\n",
    "        self._ensure_params_initialized(device, D)\n",
    "        kernel_scale = self._kernel_scale()\n",
    "\n",
    "        proj = torch.matmul(inputs, self.W * kernel_scale) + self.b\n",
    "        outputs = torch.cos(proj) * np.sqrt(2.0 / self.Nf)\n",
    "\n",
    "        if self.normalization:\n",
    "            norm = np.sqrt(self.Nf)\n",
    "            outputs = outputs / norm\n",
    "\n",
    "        return outputs.permute(0, 2, 1)  # [B, Nf, T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralDropout1d(nn.Module):\n",
    "    def __init__(self, p: float = 0.1, channels_last: bool = True):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.channels_last = channels_last\n",
    "    def forward(self, x):\n",
    "        if (not self.training) or self.p == 0.0:\n",
    "            return x\n",
    "        if self.channels_last:\n",
    "            B, T, F = x.shape\n",
    "            mask = (torch.rand(B, 1, F, device=x.device) > self.p).float() / (1.0 - self.p)\n",
    "            return x * mask\n",
    "        else:\n",
    "            B, F, T = x.shape\n",
    "            mask = (torch.rand(B, F, 1, device=x.device) > self.p).float() / (1.0 - self.p)\n",
    "            return x * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalSpectralBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bloque temporal convolucional dilatado con residual y normalizaciÃ³n.\n",
    "    Garantiza longitudes compatibles mediante recorte dinÃ¡mico.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, kernel_size=3, dilation=2, p_drop=0.1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2\n",
    "        self.conv1 = nn.Conv1d(features, features, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(features, features, kernel_size, padding=padding, dilation=1)\n",
    "        self.norm = nn.LayerNorm(features)\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "\n",
    "    def forward(self, x):  # [B,T,F]\n",
    "        res = x\n",
    "        y = x.transpose(1, 2)          # [B,F,T]\n",
    "        y = self.act(self.conv1(y))\n",
    "        y = self.conv2(y).transpose(1, 2)  # [B,T',F]\n",
    "        # Ajuste de longitud si hay diferencia\n",
    "        if y.size(1) != res.size(1):\n",
    "            min_len = min(y.size(1), res.size(1))\n",
    "            y = y[:, :min_len, :]\n",
    "            res = res[:, :min_len, :]\n",
    "        y = self.norm(y + res)\n",
    "        y = self.act(y)\n",
    "        return self.drop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBandRFFEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Aplica DenseRFF_PT sobre mÃºltiples bandas de escala y concatena las salidas.\n",
    "    Entrada: [B, T, D]\n",
    "    Salida: [B, T, F_total]\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=1, bands=(4., 24., 168.), nf_per_band=32,\n",
    "                 kernel=\"gaussian\", spectral_dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.bands = nn.ModuleList([\n",
    "            DenseRFF_PT(Nf=nf_per_band, function=\"cos\",\n",
    "                        trainable_W=True, trainable_scale=True,\n",
    "                        kernel=kernel, scale=band)\n",
    "            for band in bands\n",
    "        ])\n",
    "        self.out_dim = nf_per_band * len(self.bands)\n",
    "        self.norm = nn.LayerNorm(self.out_dim)\n",
    "        self.spec_do = SpectralDropout1d(p=spectral_dropout_p, channels_last=True)\n",
    "        self.drop = nn.Dropout(spectral_dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for b in self.bands:\n",
    "            z = b(x)                    # [B, Nf, T]\n",
    "            z = z.transpose(1, 2)       # [B, T, Nf]\n",
    "            outs.append(z)\n",
    "        zcat = torch.cat(outs, dim=2)   # [B, T, F_total]\n",
    "        zcat = self.norm(zcat)\n",
    "        zcat = self.drop(self.spec_do(zcat))\n",
    "        return zcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalHead(nn.Module):\n",
    "    \"\"\"Pooling temporal + proyecciÃ³n final.\"\"\"\n",
    "    def __init__(self, hidden, horizon, pool=\"last\"):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        self.fc1 = nn.Linear(hidden, hidden // 2)\n",
    "        self.fc2 = nn.Linear(hidden // 2, horizon)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, H):\n",
    "        if self.pool == \"mean\":\n",
    "            v = H.mean(dim=1)\n",
    "        else:\n",
    "            v = H[:, -1, :]\n",
    "        return self.fc2(self.act(self.fc1(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46295577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFF_AnyRNN_Forecaster(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura general con codificaciÃ³n RFF + bloque temporal + RNN/GRU/LSTM.\n",
    "    \"\"\"\n",
    "    def __init__(self, horizon=24, rnn_type=\"RNN\",\n",
    "                 bands=(4., 24., 168.), nf_per_band=64,\n",
    "                 hidden=96, num_layers=1, bidirectional=False,\n",
    "                 use_tsb=True, kernel=\"gaussian\",\n",
    "                 spectral_dropout_p=0.1, pool=\"last\"):\n",
    "        super().__init__()\n",
    "        # --- Codificador espectral ---\n",
    "        self.enc = MultiBandRFFEncoder(1, bands, nf_per_band, kernel, spectral_dropout_p)\n",
    "        # --- Bloque temporal convolucional ---\n",
    "        self.tsb = TemporalSpectralBlock(self.enc.out_dim) if use_tsb else nn.Identity()\n",
    "        # --- RNN parametrizable ---\n",
    "        self.rnn = getattr(nn, rnn_type)(\n",
    "            input_size=self.enc.out_dim,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        # --- ProyecciÃ³n final ---\n",
    "        out_hidden = hidden * (2 if bidirectional else 1)\n",
    "        self.head = TemporalHead(out_hidden, horizon, pool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)       # [B,T,F]\n",
    "        z = self.tsb(z)       # [B,T,F]\n",
    "        H, _ = self.rnn(z)    # [B,T,H]\n",
    "        return self.head(H)   # [B,H]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d446b",
   "metadata": {},
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalLoss(nn.Module):\n",
    "    def __init__(self, alpha_spec: float = 0.0, alpha_weight: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        # alpha_* quedan ignorados en el baseline tradicional\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        # train_model llama criterion(yb, preds): (y_true, y_pred)\n",
    "        return F.mse_loss(y_pred, y_true)\n",
    "\n",
    "def ts_augment(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, folder_name, num_epochs=50, lr=1e-3, device=\"cuda\", trial=None, lr_rho_multiplier: float = 1.0, log_per_batch: bool = False):\n",
    "    \"\"\"\n",
    "    VersiÃ³n mejorada con:\n",
    "      âœ… Compatibilidad con nuevas clases (RecurrentRFFForecast, MultiScaleRFF)\n",
    "      âœ… Data augmentation temporal (ts_augment)\n",
    "      âœ… PÃ©rdida combinada TotalLoss (Huber ponderado + Espectral)\n",
    "      âœ… Logging automÃ¡tico de â„“ (bandwidth) si el modelo usa RFF\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    import torch.optim as optim\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "    loaders = data[folder_name][\"loaders\"]\n",
    "    train_loader = loaders[\"train\"]\n",
    "    valid_loader = loaders[\"valid\"]\n",
    "    test_loader  = loaders[\"test\"]\n",
    "\n",
    "    # =============================================================\n",
    "    # Helpers internos\n",
    "    # =============================================================\n",
    "    def _iter_rff_modules(m):\n",
    "        \"\"\"Detecta mÃ³dulos tipo RFF (DenseRFF_PT o MultiScaleRFF).\"\"\"\n",
    "        target_class_names = [\"DenseRFF_PT\", \"MultiScaleRFF\"]\n",
    "        for sub in m.modules():\n",
    "            name_ok = (sub.__class__.__name__ in target_class_names)\n",
    "            has_attrs = any(hasattr(sub, a) for a in [\"kernel_scale\", \"bandwidth_lengthscale\", \"log_bandwidth\", \"scale\"])\n",
    "            if name_ok or has_attrs:\n",
    "                yield sub\n",
    "\n",
    "    def _safe_item(x):\n",
    "        try:\n",
    "            return float(x.detach().cpu().item())\n",
    "        except Exception:\n",
    "            try:\n",
    "                return float(x)\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    def _compute_ell_if_possible(rff):\n",
    "        \"\"\"Intenta obtener una 'longitud de banda' interpretable.\"\"\"\n",
    "        if hasattr(rff, \"bandwidth_lengthscale\"):\n",
    "            try:\n",
    "                ell = rff.bandwidth_lengthscale()\n",
    "                if isinstance(ell, (list, tuple)):\n",
    "                    ell = ell[0]\n",
    "                return _safe_item(ell)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            scale = getattr(rff, \"scale\", None)\n",
    "            ksc   = getattr(rff, \"kernel_scale\", None)\n",
    "            if scale is not None and ksc is not None:\n",
    "                scale = _safe_item(scale)\n",
    "                ksc   = _safe_item(ksc)\n",
    "                if scale is not None and ksc is not None and ksc != 0.0:\n",
    "                    return scale / ksc\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    # =============================================================\n",
    "    # InicializaciÃ³n de modelo y optimizador\n",
    "    # =============================================================\n",
    "    xb0, yb0 = next(iter(train_loader))\n",
    "    window  = int(xb0.shape[1])\n",
    "    horizon = int(yb0.shape[1])\n",
    "\n",
    "    if hasattr(model, \"fc2\") and isinstance(model.fc2, nn.Linear) and model.fc2.out_features != horizon:\n",
    "        model.fc2 = nn.Linear(model.fc2.in_features, horizon).to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model(xb0.to(device))\n",
    "\n",
    "    named = list(model.named_parameters())\n",
    "    rho_params   = [p for n, p in named if \"rho_scale\" in n and p.requires_grad]\n",
    "    other_params = [p for n, p in named if \"rho_scale\" not in n and p.requires_grad]\n",
    "\n",
    "    if lr_rho_multiplier != 1.0 and len(rho_params) > 0:\n",
    "        optimizer = optim.Adam(\n",
    "            [{\"params\": rho_params, \"lr\": lr * lr_rho_multiplier},\n",
    "             {\"params\": other_params, \"lr\": lr}]\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # âœ… PÃ©rdida hÃ­brida\n",
    "    criterion = TotalLoss(alpha_spec=1e-3, alpha_weight=0.05)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    history = {\"train_loss\": [], \"valid_loss\": []}\n",
    "\n",
    "    # Detectar RFFs una sola vez (tras warm-up)\n",
    "    rff_modules = list(_iter_rff_modules(model))\n",
    "    has_rff = len(rff_modules) > 0\n",
    "    ell_series = defaultdict(list)\n",
    "    rff_names = {id(m): f\"RFF_{i+1}_{m.__class__.__name__}\" for i, m in enumerate(rff_modules)}\n",
    "\n",
    "    def _log_bandwidths(step):\n",
    "        \"\"\"Calcula y guarda â„“ por cada capa RFF si es posible.\"\"\"\n",
    "        for m in rff_modules:\n",
    "            ell = _compute_ell_if_possible(m)\n",
    "            if ell is not None and np.isfinite(ell):\n",
    "                ell_series[rff_names[id(m)]].append((step, float(ell)))\n",
    "            if hasattr(m, \"log_bandwidth\"):\n",
    "                try:\n",
    "                    m.log_bandwidth(step=step)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    # =============================================================\n",
    "    # Loop de entrenamiento\n",
    "    # =============================================================\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (xb, yb) in enumerate(train_loader, start=1):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            # ðŸ”¹ AugmentaciÃ³n temporal\n",
    "            xb = ts_augment(xb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(yb, preds)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            if log_per_batch and has_rff:\n",
    "                global_step = (epoch - 1) * len(train_loader) + batch_idx\n",
    "                _log_bandwidths(step=global_step)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # -------- ValidaciÃ³n --------\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in valid_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                preds = model(xb)\n",
    "                loss = criterion(yb, preds)\n",
    "                valid_loss += loss.item() * xb.size(0)\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"valid_loss\"].append(valid_loss)\n",
    "\n",
    "        if has_rff and not log_per_batch:\n",
    "            _log_bandwidths(step=epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            msg = f\"Epoch {epoch:03d} | Train {train_loss:.4f} | Valid {valid_loss:.4f}\"\n",
    "            if has_rff:\n",
    "                name0 = next(iter(rff_names.values()))\n",
    "                last_series = ell_series.get(name0, [])\n",
    "                if last_series:\n",
    "                    msg += f\" | â„“={last_series[-1][1]:.4f}\"\n",
    "            print(msg)\n",
    "\n",
    "        if valid_loss < best_val:\n",
    "            best_val = valid_loss\n",
    "            torch.save(model.state_dict(), f\"best_model_{folder_name}.pth\")\n",
    "\n",
    "        if (trial is not None) and (\"optuna\" in globals()):\n",
    "            trial.report(-valid_loss, step=epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    # =============================================================\n",
    "    # Test y mÃ©tricas\n",
    "    # =============================================================\n",
    "    model.load_state_dict(torch.load(f\"best_model_{folder_name}.pth\", map_location=device))\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            y_true.append(yb.cpu())\n",
    "            y_pred.append(preds.cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true).numpy()\n",
    "    y_pred = torch.cat(y_pred).numpy()\n",
    "\n",
    "    # --- Global ---\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    mse  = float(mean_squared_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    print(f\"Test GLOBAL | R2={r2:.4f} | MAE={mae:.4f} | RMSE={rmse:.4f}\")\n",
    "\n",
    "    # --- Por horizonte ---\n",
    "    H = y_true.shape[1]\n",
    "    metrics_pointwise = {\"horizon\": [], \"RMSE\": [], \"MAE\": [], \"R2\": []}\n",
    "    for h in range(H):\n",
    "        yt = y_true[:, h]\n",
    "        yp = y_pred[:, h]\n",
    "        mse_h = mean_squared_error(yt, yp)\n",
    "        rmse_h = np.sqrt(mse_h)\n",
    "        mae_h  = mean_absolute_error(yt, yp)\n",
    "        r2_h   = r2_score(yt, yp)\n",
    "        metrics_pointwise[\"horizon\"].append(h+1)\n",
    "        metrics_pointwise[\"RMSE\"].append(float(rmse_h))\n",
    "        metrics_pointwise[\"MAE\"].append(float(mae_h))\n",
    "        metrics_pointwise[\"R2\"].append(float(r2_h))\n",
    "    df_pointwise = pd.DataFrame(metrics_pointwise)\n",
    "\n",
    "    # --- Acumuladas ---\n",
    "    metrics_cumulative = {\"horizon\": [], \"RMSE\": [], \"MAE\": [], \"R2\": []}\n",
    "    for h in range(1, H+1):\n",
    "        yt = y_true[:, :h].reshape(-1)\n",
    "        yp = y_pred[:, :h].reshape(-1)\n",
    "        mse_h = mean_squared_error(yt, yp)\n",
    "        rmse_h = np.sqrt(mse_h)\n",
    "        mae_h  = mean_absolute_error(yt, yp)\n",
    "        r2_h   = r2_score(yt, yp)\n",
    "        metrics_cumulative[\"horizon\"].append(h)\n",
    "        metrics_cumulative[\"RMSE\"].append(float(rmse_h))\n",
    "        metrics_cumulative[\"MAE\"].append(float(mae_h))\n",
    "        metrics_cumulative[\"R2\"].append(float(r2_h))\n",
    "    df_cumulative = pd.DataFrame(metrics_cumulative)\n",
    "\n",
    "    # --- Logging de bandwidth ---\n",
    "    \"\"\"\n",
    "    if has_rff and any(len(v) > 0 for v in ell_series.values()):\n",
    "        x_label = \"Step\" if log_per_batch else \"Epoch\"\n",
    "        for name, series in ell_series.items():\n",
    "            if not series:\n",
    "                continue\n",
    "            steps, ells = zip(*series)\n",
    "            plt.figure()\n",
    "            plt.plot(steps, ells, marker=\"o\")\n",
    "            plt.xlabel(x_label)\n",
    "            plt.ylabel(\"Bandwidth â„“ (aprox.)\")\n",
    "            plt.title(f\"EvoluciÃ³n del ancho de banda â€” {name}\")\n",
    "            plt.tight_layout()\n",
    "            out_fig = f\"bandwidth_evolution_{folder_name}_{name}.png\"\n",
    "            plt.savefig(out_fig, dpi=150)\n",
    "            print(f\"[OK] Guardado: {out_fig}\")\n",
    "\n",
    "    # --- Bandwidth logging: unified plot for all RFF layers ---\n",
    "    if has_rff and any(len(v) > 0 for v in ell_series.values()):\n",
    "\n",
    "        x_label = \"Step\" if log_per_batch else \"Epoch\"\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        for module in rff_modules:\n",
    "            key = rff_names[id(module)]\n",
    "            series = ell_series[key]\n",
    "            if not series:\n",
    "                continue\n",
    "\n",
    "            steps, ells = zip(*series)\n",
    "\n",
    "            clean_name = key.replace(\".\", \" â†’ \")\n",
    "\n",
    "            # --- Read actual mapping dimension ---\n",
    "            Nf_value = getattr(module, \"Nf\", \"?\")\n",
    "\n",
    "            legend_label = f\"{clean_name} (Nf={Nf_value})\"\n",
    "\n",
    "            plt.plot(\n",
    "                steps,\n",
    "                ells,\n",
    "                marker=\"o\",\n",
    "                linewidth=2,\n",
    "                markersize=4,\n",
    "                alpha=0.85,\n",
    "                label=legend_label\n",
    "            )\n",
    "\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(\"Bandwidth â„“ (approx.)\")\n",
    "        plt.title(f\"Bandwidth Evolution Across All RFF Layers\\nDataset: {folder_name}\")\n",
    "        plt.legend(title=\"RFF Layers\", loc=\"best\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_fig = f\"bandwidth_evolution_ALL_RFF_{folder_name}.png\"\n",
    "        plt.savefig(out_fig, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"[OK] Saved unified bandwidth plot: {out_fig}\")\n",
    "        \"\"\"\n",
    "    # --- ---\n",
    "    if has_rff and any(len(v) > 0 for v in ell_series.values()):\n",
    "\n",
    "        x_label = \"Step\" if log_per_batch else \"Epoch\"\n",
    "\n",
    "        # --- Square figure ---\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "        # Additional y-axes\n",
    "        ax2 = ax1.twinx()\n",
    "        ax3 = ax1.twinx()\n",
    "        ax3.spines[\"right\"].set_position((\"axes\", 1.18))  # shift right\n",
    "\n",
    "        # Colors\n",
    "        color_small  = \"tab:blue\"\n",
    "        color_medium = \"tab:green\"\n",
    "        color_large  = \"tab:red\"\n",
    "\n",
    "        # ============================================================\n",
    "        # Classify layers into small/medium/large â„“ groups\n",
    "        # ============================================================\n",
    "        avg_ells = [np.mean([v for _, v in s]) for s in ell_series.values() if len(s) > 0]\n",
    "        p33, p66 = np.percentile(avg_ells, [33, 66])\n",
    "\n",
    "        groups = {\"small\": [], \"medium\": [], \"large\": []}\n",
    "\n",
    "        for module in rff_modules:\n",
    "            key = rff_names[id(module)]\n",
    "            series = ell_series[key]\n",
    "            if not series:\n",
    "                continue\n",
    "\n",
    "            steps, ells = zip(*series)\n",
    "            ells = np.array(ells)\n",
    "            mean_ell = float(np.mean(ells))\n",
    "            Nf_value = getattr(module, \"Nf\", \"?\")\n",
    "\n",
    "            if mean_ell < p33:\n",
    "                groups[\"small\"].append((key, steps, ells, Nf_value))\n",
    "            elif mean_ell < p66:\n",
    "                groups[\"medium\"].append((key, steps, ells, Nf_value))\n",
    "            else:\n",
    "                groups[\"large\"].append((key, steps, ells, Nf_value))\n",
    "\n",
    "        # ============================================================\n",
    "        # Plot SMALL scale â„“ â€” ax1\n",
    "        # ============================================================\n",
    "        # Extract Nf for label (median Nf in this group)\n",
    "        small_Nf = np.median([g[3] for g in groups[\"small\"]]) if groups[\"small\"] else \"?\"\n",
    "\n",
    "        for key, steps, ells, Nf_value in groups[\"small\"]:\n",
    "            ax1.plot(\n",
    "                steps, ells,\n",
    "                marker=\"o\", linewidth=2.7, markersize=6,\n",
    "                label=f\"{key} â€” Nf={Nf_value}\",\n",
    "                color=color_small, alpha=0.92\n",
    "            )\n",
    "\n",
    "        ax1.set_xlabel(x_label, fontsize=18)\n",
    "        ax1.set_ylabel(f\"$\\mathbf{{\\\\varphi}}$ (small scale) â€” Nf={small_Nf}\", color=color_small, fontsize=18)\n",
    "        ax1.tick_params(axis=\"x\", labelsize=16)\n",
    "        ax1.tick_params(axis=\"y\", labelcolor=color_small, labelsize=16)\n",
    "        ax1.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "        # ============================================================\n",
    "        # Plot MEDIUM scale â„“ â€” ax2\n",
    "        # ============================================================\n",
    "        medium_Nf = np.median([g[3] for g in groups[\"medium\"]]) if groups[\"medium\"] else \"?\"\n",
    "\n",
    "        for key, steps, ells, Nf_value in groups[\"medium\"]:\n",
    "            ax2.plot(\n",
    "                steps, ells,\n",
    "                marker=\"s\", linewidth=2.7, markersize=6,\n",
    "                label=f\"{key} â€” Nf={Nf_value}\",\n",
    "                color=color_medium, alpha=0.92\n",
    "            )\n",
    "\n",
    "        #ax2.set_ylabel(f\"\\varphi (medium scale) â€” Nf={medium_Nf}\",\n",
    "        #              color=color_medium, fontsize=18)\n",
    "        ax2.set_ylabel(f\"$\\mathbf{{\\\\varphi}}$ (medium scale) â€” Nf={small_Nf}\",\n",
    "                      color=color_medium, fontsize=18)\n",
    "\n",
    "        ax2.tick_params(axis=\"y\", labelcolor=color_medium, labelsize=16)\n",
    "\n",
    "        # ============================================================\n",
    "        # Plot LARGE scale â„“ â€” ax3\n",
    "        # ============================================================\n",
    "        large_Nf = np.median([g[3] for g in groups[\"large\"]]) if groups[\"large\"] else \"?\"\n",
    "\n",
    "        for key, steps, ells, Nf_value in groups[\"large\"]:\n",
    "            ax3.plot(\n",
    "                steps, ells,\n",
    "                marker=\"^\", linewidth=2.7, markersize=6,\n",
    "                label=f\"{key} â€” Nf={Nf_value}\",\n",
    "                color=color_large, alpha=0.92\n",
    "            )\n",
    "\n",
    "        ax3.set_ylabel(f\"$\\mathbf{{\\\\varphi}}$ (large scale) â€” Nf={large_Nf}\",\n",
    "                      color=color_large, fontsize=18)\n",
    "        ax3.tick_params(axis=\"y\", labelcolor=color_large, labelsize=16)\n",
    "\n",
    "        # ============================================================\n",
    "        # Unified Legend (all layers + Nf)\n",
    "        # ============================================================\n",
    "        handles, labels = [], []\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            h, l = ax.get_legend_handles_labels()\n",
    "            handles += h\n",
    "            labels  += l\n",
    "\n",
    "        fig.legend(\n",
    "            handles, labels,\n",
    "            loc=\"upper center\",\n",
    "            bbox_to_anchor=(0.5, -0.08),\n",
    "            ncol=2,\n",
    "            fontsize=15,\n",
    "            title=\"RFF Layers (with Nf mapping dimension)\"\n",
    "        )\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "\n",
    "        out_fig = f\"bandwidth_{folder_name}.png\"\n",
    "        plt.savefig(out_fig, dpi=240)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"[OK] Saved triple-axis plot with Nf in axes: {out_fig}\")\n",
    "\n",
    "    return history, df_pointwise, df_cumulative, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruction_per_horizon(y_true, y_pred, num_samples=500, folder_name=\"dataset\"):\n",
    "    N, H = y_true.shape\n",
    "    num_samples = min(num_samples, N)\n",
    "\n",
    "    for h in range(H):\n",
    "        plt.figure(figsize=(14, 4))\n",
    "        plt.plot(range(num_samples), y_true[:num_samples, h],\n",
    "                 label=f\"Real (h={h+1})\", color=\"blue\", linewidth=1.5)\n",
    "        plt.plot(range(num_samples), y_pred[:num_samples, h],\n",
    "                 label=f\"Predicho (h={h+1})\", color=\"red\", linestyle=\"--\")\n",
    "        plt.title(f\"ReconstrucciÃ³n Test - {folder_name} (Horizonte {h+1})\")\n",
    "        plt.xlabel(\"Ãndice de muestra\")\n",
    "        plt.ylabel(\"Valor\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b32cd1",
   "metadata": {},
   "source": [
    "# **Hiperparametres tunnnig**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfceb9f",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plain_model_from_trial(trial, horizon, rnn_type):\n",
    "    \"\"\"\n",
    "    Construye un modelo PlainRNN_Forecaster con los mismos principios de build_model_from_trial.\n",
    "    \"\"\"\n",
    "    # --- HiperparÃ¡metros Optuna ---\n",
    "\n",
    "    hidden      = trial.suggest_int(\"hidden\", 16, 256, step=16)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "\n",
    "    # En este caso no hay RFF, asÃ­ que mantenemos estructura minimalista\n",
    "    model = PlainRNN_Forecaster(\n",
    "        horizon=horizon,\n",
    "        rnn_type=rnn_type,\n",
    "        hidden=hidden,\n",
    "        num_layers=num_layers,\n",
    "        bidirectional=False,\n",
    "        pool=\"last\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a54769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_factory_plain(data, folder_name, device, rnn_type):\n",
    "    def objective(trial):\n",
    "\n",
    "        # ---- Optimizador\n",
    "        #lr_rho_multiplier = trial.suggest_float(\"lr_rho_multiplier\", 0.5, 5.0, log=True)\n",
    "\n",
    "        # Detectar horizonte desde loaders\n",
    "        xb0, yb0 = next(iter(data[folder_name][\"loaders\"][\"train\"]))\n",
    "        horizon = int(yb0.shape[1])\n",
    "\n",
    "        # Construir modelo tradicional\n",
    "        model = build_plain_model_from_trial(trial, horizon, rnn_type).to(device)\n",
    "\n",
    "        # Entrenar usando tu funciÃ³n original train_model\n",
    "        history, df_point, df_cum, y_true, y_pred = train_model(\n",
    "            model=model,\n",
    "            data=data,\n",
    "            folder_name=folder_name,\n",
    "            num_epochs=50,\n",
    "            lr=1e-3,\n",
    "            device=device,\n",
    "            trial=trial,\n",
    "            lr_rho_multiplier=1e-3,\n",
    "            log_per_batch=False\n",
    "        )\n",
    "\n",
    "        # Usar la MEJOR pÃ©rdida de validaciÃ³n observada\n",
    "        best_valid = float(min(history[\"valid_loss\"])) if history[\"valid_loss\"] else float(\"inf\")\n",
    "\n",
    "        # Registrar valores complementarios\n",
    "        trial.set_user_attr(\"last_valid\", history[\"valid_loss\"][-1] if history[\"valid_loss\"] else None)\n",
    "\n",
    "        return best_valid\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf79d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner  = MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "\n",
    "studies_plain = {}\n",
    "best_model_cfgs = {}\n",
    "\n",
    "# Detectar horizonte (H) desde los loaders, igual que en tu esquema\n",
    "xb0, yb0 = next(iter(data[folder_name][\"loaders\"][\"train\"]))\n",
    "H = int(yb0.shape[1])\n",
    "\n",
    "for rnn_type in [\"RNN\", \"GRU\", \"LSTM\"]:\n",
    "    study_name = f\"Plain-{rnn_type} Tuning-{folder_name}\"\n",
    "    print(f\"\\n========================================\")\n",
    "    print(f\"ðŸ”§ Optuna Study: {study_name}\")\n",
    "    print(\"========================================\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "        study_name=study_name\n",
    "    )\n",
    "\n",
    "    objective = objective_factory_plain(data, folder_name, device, rnn_type)\n",
    "    study.optimize(objective, n_trials=n_trials_per_type, gc_after_trial=True)\n",
    "\n",
    "    print(\"âœ… Best trial:\", study.best_trial.number)\n",
    "    print(\"âœ… Best valid MSE:\", study.best_value)\n",
    "    print(\"âœ… Best params:\", study.best_trial.params)\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "\n",
    "    studies_plain[rnn_type] = study\n",
    "\n",
    "    # =========================================================\n",
    "    # Guardar configuraciÃ³n del mejor modelo en el esquema estÃ¡ndar\n",
    "    # =========================================================\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # Defaults para los que no se optimizan explÃ­citamente\n",
    "    hidden = best_params.get(\"hidden\", 96)\n",
    "    num_layers = best_params.get(\"num_layers\", 1)\n",
    "    #bidir = best_params.get(\"bidirectional\", False)\n",
    "    #pool = best_params.get(\"pool\", \"last\")\n",
    "\n",
    "    best_model_cfgs[rnn_type] = dict(\n",
    "        kind=\"plain\",\n",
    "        args=dict(\n",
    "            horizon=H,\n",
    "            rnn_type=rnn_type,\n",
    "            hidden=hidden,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=False,\n",
    "            pool=\"last\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# âœ… Resumen final\n",
    "print(\"\\n========================================\")\n",
    "print(\"ðŸ“¦ Estructura best_model_cfgs generada:\")\n",
    "print(\"========================================\")\n",
    "for k, v in best_model_cfgs.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a221d",
   "metadata": {},
   "source": [
    "## RFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_trial(trial, horizon, rnn_type):\n",
    "    # --- HiperparÃ¡metros Optuna ---\n",
    "\n",
    "    #kernel = trial.suggest_categorical(\"kernel\", [\"gaussian\", \"laplacian\"])\n",
    "    #use_tsb = trial.suggest_categorical(\"use_tsb\", [True, False])\n",
    "    #bidir   = trial.suggest_categorical(\"bidirectional\", [False, True])\n",
    "\n",
    "    # Multibanda\n",
    "    # Puedes fijar bandas tÃ­picas o permitir elecciÃ³n:\n",
    "    bands_preset = trial.suggest_categorical(\"bands_preset\", [\"4-24-168\", \"6-24-72\", \"12-24-168\"])\n",
    "    if bands_preset == \"4-24-168\":\n",
    "        bands = (4., 24., 168.)\n",
    "    elif bands_preset == \"6-24-72\":\n",
    "        bands = (6., 24., 72.)\n",
    "    else:\n",
    "        bands = (12., 24., 168.)\n",
    "\n",
    "    nf_per_band = trial.suggest_int(\"nf_per_band\", 16, 128, step=8)\n",
    "    hidden      = trial.suggest_int(\"hidden\", 16, 256, step=16)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    spec_do_p   = trial.suggest_float(\"spectral_dropout_p\", 0.0, 0.5, step=0.1)\n",
    "    #pool        = trial.suggest_categorical(\"pool\", [\"last\", \"mean\"])\n",
    "\n",
    "    model = RFF_AnyRNN_Forecaster(\n",
    "        horizon=horizon,\n",
    "        rnn_type=rnn_type,\n",
    "        bands=bands,\n",
    "        nf_per_band=nf_per_band,\n",
    "        hidden=hidden,\n",
    "        num_layers=num_layers,\n",
    "        bidirectional=False,\n",
    "        use_tsb=True,\n",
    "        kernel=\"gaussian\",\n",
    "        spectral_dropout_p=spec_do_p,\n",
    "        pool=\"last\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f247e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_factory(data, folder_name, device, rnn_type):\n",
    "    def objective(trial):\n",
    "\n",
    "        # ---- Optimizador\n",
    "        #lr   = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        lr_rho_multiplier = trial.suggest_float(\"lr_rho_multiplier\", 0.5, 5.0, log=True)\n",
    "        #num_epochs = trial.suggest_int(\"num_epochs\", 15, 60, step=5)  # puedes ampliar\n",
    "\n",
    "        # Detectar horizonte desde loaders\n",
    "        xb0, yb0 = next(iter(data[folder_name][\"loaders\"][\"train\"]))\n",
    "        horizon = int(yb0.shape[1])\n",
    "\n",
    "        model = build_model_from_trial(trial, horizon, rnn_type).to(device)\n",
    "\n",
    "        # Entrenar y obtener historia\n",
    "        history, df_point, df_cum, y_true, y_pred = train_model(\n",
    "            model=model,\n",
    "            data=data,\n",
    "            folder_name=folder_name,\n",
    "            num_epochs=50,\n",
    "            lr=1e-3,\n",
    "            device=device,\n",
    "            trial=trial,\n",
    "            lr_rho_multiplier=lr_rho_multiplier,\n",
    "            log_per_batch=False\n",
    "        )\n",
    "        # Usar la MEJOR pÃ©rdida de validaciÃ³n observada\n",
    "        best_valid = float(min(history[\"valid_loss\"])) if history[\"valid_loss\"] else float(\"inf\")\n",
    "\n",
    "        # (Opcional) reportar tambiÃ©n una mÃ©trica secundaria para diagnÃ³stico\n",
    "        trial.set_user_attr(\"last_valid\", history[\"valid_loss\"][-1] if history[\"valid_loss\"] else None)\n",
    "\n",
    "        return best_valid\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73082a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = names_TSF[0]\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner  = MedianPruner(n_startup_trials=5, n_warmup_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01249faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_url = \"sqlite:///optuna_results_{}.db\".format(names_TSF[0])\n",
    "\n",
    "studies = {}\n",
    "for rnn_type in [\"RNN\", \"GRU\", \"LSTM\"]:\n",
    "\n",
    "    study_name = f\"RFF-{rnn_type} Tuning-{folder_name}\"\n",
    "    print(f\"\\n========================================\\nðŸ”§ Optuna Study: {study_name}\\n========================================\")\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner, study_name=study_name,\n",
    "                                storage=storage_url, load_if_exists=True)\n",
    "\n",
    "    objective = objective_factory(data, folder_name, device, rnn_type)\n",
    "    study.optimize(objective, n_trials=n_trials_per_type, gc_after_trial=True)\n",
    "\n",
    "    print(\" Best trial:\", study.best_trial.number)\n",
    "    print(\" Best valid MSE:\", study.best_value)\n",
    "    print(\" Best params:\", study.best_trial.params)\n",
    "    print(\" \\n\\t \")\n",
    "    studies[rnn_type] = study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a23198",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['RNN', 'GRU', 'LSTM']:\n",
    "    print(\"=============================================================\")\n",
    "    print(f\"ðŸ“Š Mostrando resultados para el modelo: {model_name}\")\n",
    "    print(\"=============================================================\")\n",
    "\n",
    "    # 1. Obtener el estudio especÃ­fico\n",
    "    try:\n",
    "        study = studies[model_name]\n",
    "    except KeyError:\n",
    "        print(f\"Error: No se encontrÃ³ el estudio para '{model_name}'. Saltando...\")\n",
    "        continue\n",
    "\n",
    "    # --- GrÃ¡fico 1: Historial de OptimizaciÃ³n ---\n",
    "    print(f\"\\n--- 1. Historial de OptimizaciÃ³n ({model_name}) ---\")\n",
    "    print(\"Muestra cÃ³mo mejorÃ³ el 'score' (ej. MASE) en cada intento (trial).\")\n",
    "    try:\n",
    "        fig_history = vis.plot_optimization_history(study)\n",
    "        display(fig_history)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo generar el grÃ¡fico de historial: {e}\")\n",
    "\n",
    "    # --- GrÃ¡fico 2: Importancia de ParÃ¡metros ---\n",
    "    print(f\"\\n--- 2. Importancia de ParÃ¡metros ({model_name}) ---\")\n",
    "    print(\"Muestra quÃ© hiperparÃ¡metros impactaron mÃ¡s en el resultado final.\")\n",
    "    try:\n",
    "        fig_importance = vis.plot_param_importances(study)\n",
    "        display(fig_importance)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo generar el grÃ¡fico de importancia: {e}\")\n",
    "\n",
    "    # --- GrÃ¡fico 3: Coordenadas Paralelas (Â¡NUEVO Y MUY ÃšTIL!) ---\n",
    "    print(f\"\\n--- 3. Coordenadas Paralelas ({model_name}) ---\")\n",
    "    print(\"Cada lÃ­nea es un 'trial'. Ideal para ver quÃ© combinaciones ganan.\")\n",
    "    try:\n",
    "        fig_parallel = vis.plot_parallel_coordinate(study)\n",
    "        display(fig_parallel)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo generar el grÃ¡fico de coordenadas paralelas: {e}\")\n",
    "\n",
    "    # --- GrÃ¡fico 4: GrÃ¡fico de Corte (Slice) (Â¡NUEVO!) ---\n",
    "    print(f\"\\n--- 4. GrÃ¡fico de Corte (Slice) ({model_name}) ---\")\n",
    "    print(\"Muestra el 'score' para cada parÃ¡metro individualmente.\")\n",
    "    try:\n",
    "        fig_slice = vis.plot_slice(study)\n",
    "        display(fig_slice)\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo generar el grÃ¡fico de corte: {e}\")\n",
    "\n",
    "    # --- GrÃ¡fico 5: GrÃ¡fico de Contorno (Â¡NUEVO Y AVANZADO!) ---\n",
    "    print(f\"\\n--- 5. GrÃ¡fico de Contorno (Top 2 Params) ({model_name}) ---\")\n",
    "    print(\"Muestra la interacciÃ³n entre los 2 parÃ¡metros mÃ¡s importantes.\")\n",
    "    try:\n",
    "        # 1. Obtener las importancias (no el grÃ¡fico, sino los datos)\n",
    "        importances = optuna.importance.get_param_importances(study)\n",
    "\n",
    "        # 2. Ordenar y tomar los 2 nombres mÃ¡s importantes\n",
    "        top_2_params = sorted(importances.keys(), key=lambda x: importances[x], reverse=True)[:2]\n",
    "\n",
    "        if len(top_2_params) == 2:\n",
    "            print(f\"Analizando la interacciÃ³n entre: '{top_2_params[0]}' y '{top_2_params[1]}'\")\n",
    "            fig_contour = vis.plot_contour(study, params=top_2_params)\n",
    "            display(fig_contour)\n",
    "        else:\n",
    "            print(\"No hay suficientes parÃ¡metros (o trials) para un grÃ¡fico de contorno.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo generar el grÃ¡fico de contorno: {e}\")\n",
    "\n",
    "    print(\"\\n\\n\") # AÃ±adir espacio para el siguiente modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = data[folder_name][\"loaders\"][\"train\"].dataset.tensors[1].shape[1]\n",
    "\n",
    "#best_model_cfgs = {}\n",
    "\"\"\"\n",
    "best_model_cfgs = {\n",
    "    # ===== TRADICIONALES =====\n",
    "    \"RNN\": dict(\n",
    "        kind=\"plain\",\n",
    "        args=dict(horizon=H, rnn_type=\"RNN\",\n",
    "                  hidden=96, num_layers=1, bidirectional=False, pool=\"last\")\n",
    "    ),\n",
    "    \"GRU\": dict(\n",
    "        kind=\"plain\",\n",
    "        args=dict(horizon=H, rnn_type=\"GRU\",\n",
    "                  hidden=96, num_layers=1, bidirectional=False, pool=\"last\")\n",
    "    ),\n",
    "    \"LSTM\": dict(\n",
    "        kind=\"plain\",\n",
    "        args=dict(horizon=H, rnn_type=\"LSTM\",\n",
    "                  hidden=96, num_layers=1, bidirectional=False, pool=\"last\")\n",
    "    ),\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "for model_name, study in studies.items():\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    print(best_params)\n",
    "\n",
    "    new_args = best_params.copy()\n",
    "    new_args['horizon'] = H\n",
    "    new_args['rnn_type'] = model_name\n",
    "    new_args['bidirectional'] = False\n",
    "    new_args['use_tsb'] = True\n",
    "    new_args['kernel'] = \"gaussian\"\n",
    "    new_args['spectral_dropout_p'] = best_params['spectral_dropout_p']\n",
    "    new_args['pool'] = \"last\"\n",
    "    new_args['bands_preset'] = best_params['bands_preset']\n",
    "    new_args['nf_per_band'] = best_params['nf_per_band']\n",
    "    new_args['hidden'] = best_params['hidden']\n",
    "    new_args['num_layers'] = best_params['num_layers']\n",
    "\n",
    "\n",
    "    config_key = f\"RFF_{model_name}\"\n",
    "\n",
    "    partes_str = new_args['bands_preset'].split('-')\n",
    "    bands_tupla = tuple(int(p) for p in partes_str)\n",
    "\n",
    "    best_model_cfgs[config_key] = dict(\n",
    "        kind=\"rff\",\n",
    "        args=dict(horizon=H,\n",
    "                  rnn_type=new_args['rnn_type'],\n",
    "                  bands=bands_tupla,\n",
    "                  nf_per_band=new_args['nf_per_band'],\n",
    "                  hidden=new_args['hidden'],\n",
    "                  num_layers=new_args['num_layers'],\n",
    "                  bidirectional=False,\n",
    "                  use_tsb=True,\n",
    "                  kernel=\"gaussian\",\n",
    "                  spectral_dropout_p=new_args['spectral_dropout_p'],\n",
    "                  pool=\"last\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474344d",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd94105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===========================================================\n",
    "# CONFIGURACIÃ“N DE ENTRENAMIENTO\n",
    "# ===========================================================\n",
    "train_cfg = dict(\n",
    "    num_epochs=100,\n",
    "    log_per_batch=False\n",
    ")\n",
    "\n",
    "# ===========================================================\n",
    "# DICCIONARIO MAESTRO PARA GUARDAR TODO\n",
    "# ===========================================================\n",
    "experiment_results = {\n",
    "    \"config\": {\n",
    "        \"train_cfg\": train_cfg,\n",
    "        \"folder_name\": folder_name,\n",
    "        \"timestamp\": time.time(),\n",
    "        \"models_included\": list(best_model_cfgs.keys())\n",
    "    },\n",
    "    \"global\": {\n",
    "        \"pointwise_all\": pd.DataFrame(),\n",
    "        \"cumulative_all\": pd.DataFrame()\n",
    "    },\n",
    "    \"models\": {}\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "# ===========================================================\n",
    "# LOOP DE ENTRENAMIENTO PARA CADA MODELO\n",
    "# ===========================================================\n",
    "for name, cfg in best_model_cfgs.items():\n",
    "    print(f\"\\n===============================\")\n",
    "    print(f\" Entrenando modelo: {name}\")\n",
    "    print(f\"===============================\")\n",
    "\n",
    "    kind = cfg[\"kind\"]\n",
    "    args = cfg[\"args\"]\n",
    "\n",
    "    # ===== Inicializar modelo =====\n",
    "    if kind == \"plain\":\n",
    "        allowed_keys = {\"horizon\", \"rnn_type\", \"hidden\", \"num_layers\", \"bidirectional\", \"pool\"}\n",
    "        clean_args = {k: v for k, v in args.items() if k in allowed_keys}\n",
    "        model = PlainRNN_Forecaster(**clean_args).to(device)\n",
    "\n",
    "    elif kind == \"rff\":\n",
    "        model = RFF_AnyRNN_Forecaster(**args).to(device)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de modelo desconocido: {kind}\")\n",
    "\n",
    "    # ===== ENTRENAMIENTO =====\n",
    "    start = time.time()\n",
    "    history, df_pointwise, df_cumulative, y_true, y_pred = train_model(\n",
    "        model=model,\n",
    "        data=data,\n",
    "        folder_name=folder_name,\n",
    "        device=device,\n",
    "        **train_cfg\n",
    "    )\n",
    "    end = time.time()\n",
    "\n",
    "    # AÃ±adir columna del modelo\n",
    "    df_pointwise[\"model\"] = name\n",
    "    df_cumulative[\"model\"] = name\n",
    "\n",
    "    # ===== ACUMULAR EN LOS GLOBALES =====\n",
    "    experiment_results[\"global\"][\"pointwise_all\"] = pd.concat(\n",
    "        [experiment_results[\"global\"][\"pointwise_all\"], df_pointwise],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    experiment_results[\"global\"][\"cumulative_all\"] = pd.concat(\n",
    "        [experiment_results[\"global\"][\"cumulative_all\"], df_cumulative],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # ===== GUARDAR RESULTADOS POR MODELO =====\n",
    "    model_entry = {\n",
    "        \"kind\": kind,\n",
    "        \"args\": args,\n",
    "        \"history\": history,                 # dict con train/valid por epoch\n",
    "        \"pointwise\": df_pointwise,          # DataFrame\n",
    "        \"cumulative\": df_cumulative,        # DataFrame\n",
    "        \"forecast\": {\n",
    "            \"y_true\": y_true,               # np.array\n",
    "            \"y_pred\": y_pred                # np.array\n",
    "        },\n",
    "        \"summary\": {\n",
    "            \"final_train_loss\": float(np.round(history.get(\"train_loss\", [np.nan])[-1], 6)),\n",
    "            \"final_valid_loss\": float(np.round(history.get(\"valid_loss\", [np.nan])[-1], 6)),\n",
    "            \"train_time_min\": float(np.round((end - start) / 60, 2))\n",
    "        }\n",
    "    }\n",
    "\n",
    "    experiment_results[\"models\"][name] = model_entry\n",
    "    results_summary.append(model_entry[\"summary\"])\n",
    "\n",
    "# ===========================================================\n",
    "# RESUMEN FINAL\n",
    "# ===========================================================\n",
    "df_summary = pd.DataFrame(results_summary)\n",
    "experiment_results[\"global\"][\"summary\"] = df_summary\n",
    "\n",
    "print(\"\\n======= RESUMEN FINAL =======\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad809ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"/content/results_{folder_name}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(experiment_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bef8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = [\"R2\", \"MAE\", \"RMSE\"]\n",
    "\n",
    "# === NUEVO: Obtener los datos del diccionario maestro ===\n",
    "df_pointwise_all = experiment_results[\"global\"][\"pointwise_all\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # ----- Modelos SIN RFF -----\n",
    "    for name in [\"RNN\", \"GRU\", \"LSTM\"]:\n",
    "        subset = df_pointwise_all[df_pointwise_all[\"model\"] == name]\n",
    "        if not subset.empty:\n",
    "            ax.plot(\n",
    "                subset[\"horizon\"],\n",
    "                subset[metric],\n",
    "                linestyle=\"--\",\n",
    "                marker='o',\n",
    "                label=f\"{name}\"\n",
    "            )\n",
    "\n",
    "    # ----- Modelos CON RFF -----\n",
    "    for name in [\"RFF_RNN\", \"RFF_GRU\", \"RFF_LSTM\"]:\n",
    "        subset = df_pointwise_all[df_pointwise_all[\"model\"] == name]\n",
    "        if not subset.empty:\n",
    "            ax.plot(\n",
    "                subset[\"horizon\"],\n",
    "                subset[metric],\n",
    "                linestyle=\"-\",\n",
    "                marker='s',\n",
    "                label=name\n",
    "            )\n",
    "\n",
    "    ax.set_title(metric, fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Prediction horizon (h)\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.legend(title=\"Modelo\", fontsize=9)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94219b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================================================\n",
    "# OBTENER LOS DATOS DESDE experiment_results\n",
    "# ===========================================================\n",
    "df_pointwise_all = experiment_results[\"global\"][\"pointwise_all\"].copy()\n",
    "\n",
    "metrics = [\"R2\", \"MAE\", \"RMSE\"]\n",
    "\n",
    "# ===========================================================\n",
    "# CONSTRUIR VERSION ACUMULADA PARA GRAFICAR\n",
    "# ===========================================================\n",
    "df_cumulative_plot = (\n",
    "    df_pointwise_all\n",
    "    .sort_values([\"model\", \"horizon\"])\n",
    "    .groupby(\"model\", group_keys=False)\n",
    "    .apply(lambda g: g.assign(\n",
    "        R2=g[\"R2\"].expanding().mean(),\n",
    "        MAE=g[\"MAE\"].expanding().mean(),\n",
    "        RMSE=g[\"RMSE\"].expanding().mean()\n",
    "    ))\n",
    ")\n",
    "\n",
    "# ===========================================================\n",
    "# FIGURA MULTIPANEL\n",
    "# ===========================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # ----- Modelos SIN RFF -----\n",
    "    for name in [\"RNN\", \"GRU\", \"LSTM\"]:\n",
    "        subset = df_cumulative_plot[df_cumulative_plot[\"model\"] == name]\n",
    "        if not subset.empty:\n",
    "            ax.plot(\n",
    "                subset[\"horizon\"],\n",
    "                subset[metric],\n",
    "                linestyle=\"--\",\n",
    "                marker='o',\n",
    "                label=f\"{name}\"\n",
    "            )\n",
    "\n",
    "    # ----- Modelos CON RFF -----\n",
    "    for name in [\"RFF_RNN\", \"RFF_GRU\", \"RFF_LSTM\"]:\n",
    "        subset = df_cumulative_plot[df_cumulative_plot[\"model\"] == name]\n",
    "        if not subset.empty:\n",
    "            ax.plot(\n",
    "                subset[\"horizon\"],\n",
    "                subset[metric],\n",
    "                linestyle=\"-\",\n",
    "                marker='s',\n",
    "                label=name\n",
    "            )\n",
    "\n",
    "    # Etiquetas y estilo\n",
    "    ax.set_title(metric, fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Prediction horizon (h)\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.legend(title=\"Modelo\", fontsize=9)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b081fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# GRAFICAR PRONÃ“STICOS POR HORIZONTE (H pasos adelante)\n",
    "# ===========================================================\n",
    "\n",
    "H = experiment_results[\"config\"][\"models_included\"][0]  # o el valor que tÃº uses para horizon\n",
    "# Si horizon estÃ¡ en args:\n",
    "H = list(experiment_results[\"models\"].values())[0][\"args\"][\"horizon\"]\n",
    "\n",
    "# Acceder a los pronÃ³sticos\n",
    "forecast_dict = {\n",
    "    model_name: (\n",
    "        model_info[\"forecast\"][\"y_true\"],\n",
    "        model_info[\"forecast\"][\"y_pred\"]\n",
    "    )\n",
    "    for model_name, model_info in experiment_results[\"models\"].items()\n",
    "}\n",
    "\n",
    "for i in range(H):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    target_plotted = False\n",
    "\n",
    "    for model_name, (y_true_data, y_pred_data) in forecast_dict.items():\n",
    "\n",
    "        # Recuperar y_true una sola vez\n",
    "        if not target_plotted:\n",
    "            y_true = y_true_data[0:50, i]        # primeros 50 puntos\n",
    "            plt.plot(y_true, label=\"Target\",\n",
    "                     linestyle='dashed', color='black')\n",
    "            target_plotted = True\n",
    "\n",
    "        # PredicciÃ³n del modelo\n",
    "        y_pred = y_pred_data[0:50, i]\n",
    "        plt.plot(y_pred, label=model_name)\n",
    "\n",
    "    # ===== CONFIGURACIÃ“N DEL GRÃFICO =====\n",
    "    plt.xlim(0, 50)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Wind speed forecast\")\n",
    "    plt.title(f\"Forecast horizon h = {i+1}\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    # leyenda centrada abajo\n",
    "    plt.legend(\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, -0.2),\n",
    "        ncol=len(forecast_dict) + 1,\n",
    "        fancybox=True,\n",
    "        shadow=True\n",
    "    )\n",
    "\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import TargetTags\n",
    "test_loader = data[folder_name]['loaders']['test']\n",
    "X_batch, Y_batch = next(iter(test_loader))\n",
    "batch_index = 7  # punto de prueba a graficar\n",
    "\n",
    "# NÃºmero de pasos de entrada\n",
    "L_in = 20\n",
    "\n",
    "# ===========================================================\n",
    "# 1. RECUPERAR EL VALOR MAX PARA ESCALAR\n",
    "# ===========================================================\n",
    "max_value = data_dict_loaded[names_TSF[0]]['Max']\n",
    "\n",
    "# ===========================================================\n",
    "# 2. EXTRAER LA SERIE DE ENTRADA DEL BATCH SELECCIONADO\n",
    "# ===========================================================\n",
    "input_ts = X_batch[batch_index, :, 0].numpy() * max_value\n",
    "time = np.arange(0, input_ts.shape[0] + H + 1, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Plot ventana de entrada\n",
    "time_input = time[:input_ts.shape[0]]\n",
    "plt.plot(time_input, input_ts, label='Window', color='darkblue', linewidth=2)\n",
    "\n",
    "# ===========================================================\n",
    "# 3. DICCIONARIO DE PRONÃ“STICOS\n",
    "# ===========================================================\n",
    "forecast_dict = {\n",
    "    model_name: (\n",
    "        model_info[\"forecast\"][\"y_true\"],\n",
    "        model_info[\"forecast\"][\"y_pred\"]\n",
    "    )\n",
    "    for model_name, model_info in experiment_results[\"models\"].items()\n",
    "}\n",
    "\n",
    "# ===========================================================\n",
    "# 4. PLOT DEL TARGET + PLOTS DE CADA MODELO\n",
    "# ===========================================================\n",
    "flag = 0\n",
    "\n",
    "for model_name, (y_true_data, y_pred_data) in forecast_dict.items():\n",
    "\n",
    "    if flag == 0:\n",
    "        # ------- TARGET -------\n",
    "        target = y_true_data[batch_index, :] * max_value\n",
    "        time_target = time[input_ts.shape[0] - 1 : input_ts.shape[0] + H]\n",
    "        y_input_target = np.concatenate(([input_ts[-1]], target))\n",
    "\n",
    "        plt.plot(time_target, y_input_target,\n",
    "                 label='Target', color='black', linewidth=2)\n",
    "        flag = 1  # para que solo se grafique una vez\n",
    "\n",
    "    # ------- PRONÃ“STICO DEL MODELO -------\n",
    "    output = y_pred_data[batch_index, :] * max_value\n",
    "    time_forecast = time[input_ts.shape[0] - 1 : input_ts.shape[0] + H]\n",
    "    y_forecast = np.concatenate(([input_ts[-1]], output))\n",
    "\n",
    "    plt.plot(\n",
    "        time_forecast,\n",
    "        y_forecast,\n",
    "        label=model_name,\n",
    "        linestyle='--',\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# ===========================================================\n",
    "# 5. LÃNEA VERTICAL SEPARANDO INPUT Y FORECAST\n",
    "# ===========================================================\n",
    "plt.axvline(\n",
    "    x=input_ts.shape[0] - 1,\n",
    "    color='black',\n",
    "    linestyle=':',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# ===========================================================\n",
    "# 6. CONFIGURACIÃ“N FINAL DEL GRÃFICO\n",
    "# ===========================================================\n",
    "plt.title(\"Window â†’ Forecast horizon\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Wind speed\")\n",
    "\n",
    "plt.xlim(0, time[-1])\n",
    "\n",
    "plt.legend(\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    "    ncol=len(forecast_dict) + 1,\n",
    "    fancybox=True,\n",
    "    shadow=True\n",
    ")\n",
    "\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
